{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:19:07.761997Z",
     "start_time": "2024-05-11T09:19:02.592899Z"
    },
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# import faiss\n",
    "from voyager import Index, Space\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.backends else 'cpu')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc83bd47c61daedf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:19:24.115571Z",
     "start_time": "2024-05-11T09:19:07.762885Z"
    }
   },
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "298ad2d3",
   "metadata": {},
   "source": [
    "def process_folders(root_folder):\n",
    "    folder_data = []\n",
    "    for folder, _, files in os.walk(root_folder):\n",
    "        dmate_file = [f for f in files if f.endswith('.dmate')]\n",
    "        if dmate_file:\n",
    "            dmate_file_path = os.path.join(folder, dmate_file[0])\n",
    "            with open(dmate_file_path, 'r') as file:\n",
    "                dmate_content = file.read()\n",
    "                folder_data.append(\n",
    "                    {\n",
    "                        'folder_path': folder,\n",
    "                        'content': dmate_content,\n",
    "                        'content_emb': model.encode(dmate_content)\n",
    "                    }\n",
    "                )\n",
    "    return pd.DataFrame(folder_data)\n",
    "process_folders(\"/Users/filin_va/ML/projects\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1adef3dcd1b7a9ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T09:19:24.116701Z",
     "start_time": "2024-05-11T09:19:24.116655Z"
    }
   },
   "source": [
    "# Set the base directory\n",
    "folder_path = '../data/raw'\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "object_dict = {}\n",
    "\n",
    "# Walk through the directory\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    # Add files to the dictionary with their relative paths\n",
    "    for file in files:\n",
    "        relative_path = '../data/raw' + '/' + os.path.relpath(os.path.join(root, file), folder_path)\n",
    "        object_dict[relative_path] = \"file\"\n",
    "\n",
    "    # Add directories to the dictionary with their relative paths\n",
    "    for dir in dirs:\n",
    "        relative_path = '../data/raw' + '/' + os.path.relpath(os.path.join(root, dir), folder_path)\n",
    "        object_dict[relative_path] = \"folder\"\n",
    "\n",
    "# Get only those files that end with \".dmate\"\n",
    "dmate_files = [file for file in object_dict if file.endswith(\".dmate\")]\n",
    "\n",
    "# Print the dictionary\n",
    "# print(object_dict)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2897d2f27af4a81",
   "metadata": {},
   "source": [
    "object_dict"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8dfe4ac29ed97adb",
   "metadata": {},
   "source": [
    "def normalise_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalise the text in the form of a string, removing technical symbols and stripping leading and trailing whitespace\n",
    "    :param text: input string to be normalised\n",
    "    :return: a normalised string\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2afa7911fe4a3f24",
   "metadata": {},
   "source": [
    "# let's create a DataFrame with dmate_files paths and their content\n",
    "dmate_date = [] \n",
    "for dmate_file in dmate_files:\n",
    "    with open(dmate_file) as file:\n",
    "        input_text = file.read()\n",
    "        dmate_date.append(\n",
    "            {\n",
    "                'file_path': dmate_file,\n",
    "                'folder_path': dmate_file[:-6],\n",
    "                'content': normalise_text(input_text),\n",
    "                'content_emb': model.encode(input_text)\n",
    "            }\n",
    "        )\n",
    "\n",
    "dmate_date = pd.DataFrame(dmate_date)\n",
    "dmate_date"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0518487",
   "metadata": {},
   "source": [
    "# get all files in downloaded\n",
    "# Get the path to the Downloads folder for the current user\n",
    "downloads_path = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "\n",
    "# List all files in the Downloads folder\n",
    "files = os.listdir(downloads_path)\n",
    "test_download_file = 'documate_test.txt'\n",
    "print(files)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "542c40d7c867f085",
   "metadata": {},
   "source": [
    "with open(downloads_path+'/'+test_download_file) as dfile:\n",
    "    query = dfile.read()\n",
    "query"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfd20b151569c17d",
   "metadata": {},
   "source": [
    "query_emb = model.encode(\n",
    "    query, convert_to_tensor=True, show_progress_bar=False, batch_size=128\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f82d929077d8189e",
   "metadata": {},
   "source": [
    "torch.Tensor(dmate_date['content_emb'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9f6674ba",
   "metadata": {},
   "source": [
    "# F.softmax(torch.Tensor(dmate_date['content_emb'])[:, np.newaxis].to(device) @ query_emb[:, np.newaxis]).ravel()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f43e671e",
   "metadata": {},
   "source": [
    "n_class = np.argmax(util.cos_sim(torch.Tensor(dmate_date['content_emb']).to(device), query_emb[np.newaxis, :]).ravel().cpu())\n",
    "n_class"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b11bae3f",
   "metadata": {},
   "source": [
    "dmate_date.iloc[int(n_class)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e437011366a1160a",
   "metadata": {},
   "source": [
    "n_class = np.argmax((F.softmax(torch.Tensor(dmate_date['content_emb'])[:, np.newaxis].to(device) @ query_emb[:, np.newaxis]).ravel()).cpu().numpy())\n",
    "n_class"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d808e08",
   "metadata": {},
   "source": [
    "dmate_date['folder_path'][n_class]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c92d121d4c22b718",
   "metadata": {},
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "shutil.move(downloads_path+'/'+test_download_file, dmate_date['folder_path'][n_class])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "20508bf85a82d5f5",
   "metadata": {},
   "source": [
    "# 1. create classes extracting from the files. pdf ->\n",
    "# 2. model\n",
    "# 3. optimize code for prod\n",
    "# 4. [ideal] wrap it up - ideally with frontend; just like an app\n",
    "# 5. MLOps\n",
    "# 6. experiments"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fee48686",
   "metadata": {},
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def summarize_text(text):\n",
    "    summarizer = pipeline(\"summarization\")\n",
    "    summary = summarizer(text, max_length=150, min_length=30, do_sample=False)\n",
    "    return summary[0]['summary_text']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7771c375",
   "metadata": {},
   "source": [
    "t = \"\"\"\n",
    "\n",
    "I got gensim to work in Google Collab by following this process:\n",
    "\n",
    "!pip install gensim\n",
    "from gensim.summarization import summarize\n",
    "\n",
    "Then I was able to call summarize(some_text)\n",
    "\n",
    "Now I'm trying to run the same thing in VS code:\n",
    "\n",
    "I've installed gensim: pip3 install gensim\n",
    "\n",
    "but when I run\n",
    "\n",
    "from gensim.summarization import summarize\n",
    "\n",
    "I get the error\n",
    "\n",
    "Import \"gensim.summarization\" could not be resolvedPylancereportMissingImports\n",
    "\n",
    "I've also tried from gensim.summarization.summarizer import summarize with same error. Regardless I haven't been able to call the function summarize(some_text) outside of Google Collab.\n",
    "\n",
    "\"\"\"\n",
    "k = summarize_text(t)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "338780ce",
   "metadata": {},
   "source": [
    "k"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10434a49",
   "metadata": {},
   "source": [
    "'/Users/filin_va/Downloads/09.04.02 Искусственный интеллект в промышленности 2024.pd'.split(\"/\")[-1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2768ffed",
   "metadata": {},
   "source": [
    "int(np.argmax(torch.Tensor([0.1755, 0.1800, 0.1679, 0.1577, 0.1556, 0.1634])))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41374c4a",
   "metadata": {},
   "source": [
    "import fitz\n",
    "def get_pdf_text(file_path: str) -> str:\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as pdf:\n",
    "        for page_num in range(pdf.page_count):\n",
    "            page = pdf.load_page(page_num)\n",
    "            text += page.get_text(\"text\")\n",
    "    return text\n",
    "\n",
    "get_pdf_text(\"/Users/filin_va/Downloads/Dubai_Tour_Agreement.pdf\").split(\" \")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473ad38",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
